{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "408a0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8b240061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class NetworkLogDataset(Dataset):\n",
    "    def __init__(self, X_cat, X_num, y):\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_cat[idx], self.X_num[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c9db80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self,categorical_cardinalities,num_numerical, emb_dim=16, num_heads=2, ff_hidden=64):\n",
    "        super(TabTransformer,self).__init__()\n",
    "\n",
    "        # Embedding Layers\n",
    "\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cardinality,emb_dim) for cardinality in categorical_cardinalities\n",
    "        ])\n",
    "\n",
    "        self.num_categoricals =  len(categorical_cardinalities)\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim,nhead=num_heads,batch_first=True)\n",
    "        self.transformer=nn.TransformerEncoder(encoder_layer,num_layers=1)\n",
    "        \n",
    "        # LayerNorm for numerical features\n",
    "        self.norm_num = nn.LayerNorm(num_numerical)\n",
    "\n",
    "        # MLP classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim*self.num_categoricals+num_numerical,ff_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.3),\n",
    "            nn.Linear(ff_hidden,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self,x_cat,x_num):\n",
    "        embeds= [emb(x_cat[:,i])for i,emb in enumerate(self.embeddings)]\n",
    "        x_cat_emb=torch.stack(embeds,dim=1)\n",
    "\n",
    "        x_transformed=self.transformer(x_cat_emb)\n",
    "        x_flat=x_transformed.flatten(1)\n",
    "        x_num_norm=self.norm_num(x_num)\n",
    "        x_full = torch.cat([x_flat,x_num_norm],dim=1)\n",
    "\n",
    "        return self.fc(x_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0f4a0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.read_csv(\"../../../data/starter/train_val_data/x_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "x_val=pd.read_csv(\"../../../data/starter/train_val_data/x_val.csv\").drop(columns=['Unnamed: 0'])\n",
    "y_train=pd.read_csv(\"../../../data/starter/train_val_data/y_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "y_val=pd.read_csv(\"../../../data/starter/train_val_data/y_val.csv\").drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8ad45d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../resources/data_preprocessing/label_encoders.pkl\",\"rb\") as f:\n",
    "    labels_encoder=pickle.load(f)\n",
    "num_col = [col for col in x_train.columns if col not in labels_encoder.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0bb837d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.0393 | Val Loss: 0.0001 | Val Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     58\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 59\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     62\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\hafsa\\anaconda3\\envs\\Prediction\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hafsa\\anaconda3\\envs\\Prediction\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\hafsa\\anaconda3\\envs\\Prediction\\lib\\site-packages\\torch\\optim\\adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    155\u001b[0m         group,\n\u001b[0;32m    156\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m         state_steps)\n\u001b[1;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\hafsa\\anaconda3\\envs\\Prediction\\lib\\site-packages\\torch\\optim\\adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hafsa\\anaconda3\\envs\\Prediction\\lib\\site-packages\\torch\\optim\\adam.py:432\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    430\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    434\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Cardinalities for embedding layers\n",
    "categorical_cardinates = [len(label_encoder.classes_) for label_encoder in labels_encoder.values()]\n",
    "\n",
    "# Dataset & DataLoader\n",
    "dataset_train = NetworkLogDataset(\n",
    "    x_train[list(labels_encoder.keys())].values,\n",
    "    x_train[num_col].values,\n",
    "    y_train.values\n",
    ")\n",
    "dataset_val = NetworkLogDataset(\n",
    "    x_val[list(labels_encoder.keys())].values,\n",
    "    x_val[num_col].values,\n",
    "    y_val.values\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=64)\n",
    "\n",
    "# Initialize model\n",
    "model = TabTransformer(\n",
    "    categorical_cardinates,\n",
    "    num_numerical=x_train[num_col].shape[1]\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "losses_train=[]\n",
    "losses_val=[]\n",
    "accuracy_val=[]\n",
    "accuracy_train=[]\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    for x_cat, x_num, y_batch in loop:\n",
    "        x_cat = x_cat.to(device)\n",
    "        x_num = x_num.to(device)\n",
    "        y_batch = y_batch.to(device).float().squeeze()\n",
    "\n",
    "        preds = model(x_cat, x_num).squeeze()\n",
    "        loss = criterion(preds, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        correct_train += (preds == y_batch).sum().item()\n",
    "        total_train += y_batch.size(0)\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_cat_val, x_num_val, y_val in val_loader:\n",
    "            x_cat_val = x_cat_val.to(device)\n",
    "            x_num_val = x_num_val.to(device)\n",
    "            y_val = y_val.to(device).float().squeeze()\n",
    "\n",
    "            val_preds = model(x_cat_val, x_num_val).squeeze()\n",
    "            v_loss = criterion(val_preds, y_val)\n",
    "            val_loss += v_loss.item()\n",
    "\n",
    "            predicted = (val_preds > 0.5).float()\n",
    "            correct += (predicted == y_val).sum().item()\n",
    "            total += y_val.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "          f\"Val Acc: {correct/total:.4f}\")\n",
    "    losses_train=losses_train+[train_loss/len(train_loader)]\n",
    "    losses_val=losses_val+[val_loss/len(val_loader)]\n",
    "    accuracy_val=accuracy_val+[correct/total]\n",
    "    accuracy_train=accuracy_train+[correct_train/total_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf1987a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../../../resources/model/tab_transformer_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c578fb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23b9bef14e0>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
